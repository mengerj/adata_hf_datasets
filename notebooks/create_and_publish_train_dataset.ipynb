{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and publishing a hugging face dataset with references to anndata files. \n",
    "\n",
    "Can for example be used to train multimodal models with mmcontext. The datasets consist of a reference to a sample of an anndata file,\n",
    "which can be stored locally or remotly on nextcloud. \n",
    "\n",
    "Use the initial embedder to include some initial embeddings into our anndata object which can then be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adata_hf_datasets.utils import setup_logging\n",
    "\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "\n",
    "data_name = \"cellxgene_pseudo_bulk\"\n",
    "adata = anndata.read_h5ad(f\"../data/RNA/raw/{data_name}.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"natural_language_annotation\"]\n",
    "caption_key = \"natural_language_annotation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete objects that are not needed and are taking up space\n",
    "del adata.obsm[\"natural_language_annotation_replicates\"]\n",
    "del adata.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 14:48:30,720 - adata_hf_datasets.initial_embedder - INFO - Fitting method 'pca' with embedding_dim=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 14:48:30,721 - adata_hf_datasets.initial_embedder - INFO - Fitting PCA with 64 components.\n"
     ]
    }
   ],
   "source": [
    "from adata_hf_datasets.initial_embedder import InitialEmbedder\n",
    "\n",
    "method = \"pca\"\n",
    "dataset_name = f\"{data_name}_{method}\"\n",
    "\n",
    "embedder = InitialEmbedder(method=method)\n",
    "embedder.fit(adata)\n",
    "embedder.embed(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adata_hf_datasets.utils import split_anndata\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_dir = Path().resolve().parents[0]\n",
    "train_path = f\"{project_dir}/data/RNA/processed/{method}/{data_name}/train.h5ad\"\n",
    "val_path = f\"{project_dir}/data/RNA/processed/{method}/{data_name}/val.h5ad\"\n",
    "os.makedirs(os.path.dirname(train_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(val_path), exist_ok=True)\n",
    "train_data, val_adata = split_anndata(adata, train_size=0.9)\n",
    "train_data.write(train_path)\n",
    "val_adata.write(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_remote_path = f\"datasets/{method}/train/bowel_disease.h5ad\"\n",
    "val_remote_path = f\"datasets/{method}/val/bowel_disease.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "nextcloud_config = {\n",
    "    \"url\": \"https://nxc-fredato.imbi.uni-freiburg.de\",\n",
    "    \"username\": \"NEXTCLOUD_USER\",  # env will we obtained within code\n",
    "    \"password\": \"NEXTCLOUD_PASSWORD\",\n",
    "    \"remote_path\": \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 14:36:00,605 - datasets - INFO - PyTorch version 2.6.0 available.\n",
      "2025-02-07 14:38:57,374 - root - INFO - File saved locally at /Users/mengerj/repos/adata_hf_datasets/data/scRNA/processed/pca/cellxgene_pseudo_bulk/train.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: datasets\n",
      "Directory already exists: pca\n",
      "Directory already exists: train\n"
     ]
    }
   ],
   "source": [
    "from adata_hf_datasets.adata_ref_ds import AnnDataSetConstructor\n",
    "from adata_hf_datasets.adata_ref_ds import SimpleCaptionConstructor\n",
    "from datasets import DatasetDict\n",
    "\n",
    "hf_dataset = DatasetDict()\n",
    "# Create caption constructor with desired obs keys\n",
    "for split, path in zip([\"train\", \"val\"], [train_path, val_path]):\n",
    "    caption_constructor = SimpleCaptionConstructor(obs_keys=caption_key)\n",
    "    nextcloud_config[\"remote_path\"] = eval(f\"{split}_remote_path\")\n",
    "    constructor = AnnDataSetConstructor(\n",
    "        caption_constructor=caption_constructor,\n",
    "        store_nextcloud=True,\n",
    "        nextcloud_config=nextcloud_config,\n",
    "    )\n",
    "    constructor.add_anndata(file_path=path)\n",
    "    # Get dataset\n",
    "    dataset = constructor.get_dataset()\n",
    "    hf_dataset[split] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303edd8f1a29403fbc73bb50e81aef3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82adaf07610b44a9b661a469b3242d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2737fc70a91048dd92716690c5ef517b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8106d29b4faa46d29bca541ff02cdc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from adata_hf_datasets.utils import annotate_and_push_dataset\n",
    "\n",
    "caption_generation = f\"\"\"Captions were generated with the SimpleCaptionConstructor class. That means the previosly added annotation from the\n",
    "                following obs_keys were concatenated: {caption_constructor.obs_keys}.\"\"\"\n",
    "\n",
    "embedding_generation = f\"\"\"Embeddings were generated with the InitialEmbedder class from the adata_hf_datasets package, with method = {method}, they have \n",
    "        {embedder.embedding_dim} dimensions, and are stored in adata.obsm['X_{method}']\"\"\"\n",
    "\n",
    "annotate_and_push_dataset(\n",
    "    dataset=hf_dataset,\n",
    "    caption_generation=caption_generation,\n",
    "    embedding_generation=embedding_generation,\n",
    "    repo_id=f\"jo-mengr/{dataset_name}\",\n",
    "    readme_template_name=\"cellxgene_pseudo_bulk\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360df51d131c41abb2af04d71d5f551d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/233k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b56927fdd0d46b9993affb28beeb0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/233k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427f9fc1249440c583d3298d25d490a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e22222c84f04d38bfb4774490492eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_loaded = load_dataset(f\"jo-mengr/{dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['anndata_ref', 'caption', 'label'],\n",
       "        num_rows: 20114\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['anndata_ref', 'caption', 'label'],\n",
       "        num_rows: 20114\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_loaded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
